# Federated Learning

>*人工智能（Artificial Intelligence, AI）进入以深度学习为主导的大数据时代，基于大数据的机器学习既推动了AI的蓬勃发展，也带来了一系列安全隐患。这些隐患来源于深度学习本身的学习机制，无论是在它的模型建造（训练）阶段，还是在模型推理和使用阶段。这些安全隐患如果被有意或无意地滥用，后果将十分严重。*
---

**联邦学习是一种 <font color=#B22222>隐私保护、数据本地存储与计算</font> 的机器学习算法。**

## 文献参考  
### 1. 文献综述
* [Advances and Open Problems in Federated Learning](https://arxiv.org/pdf/1912.04977.pdf)
* [Federated Machine Learning: Concept and Applications](https://arxiv.org/pdf/1902.04885.pdf)
* [Threats to Federated Learning: A Survey](https://arxiv.org/pdf/2003.02133.pdf)
* [A Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1907.09693v3.pdf)
* [Survey of Personalization Techniques for Federated Learning](https://arxiv.org/pdf/2003.08673.pdf)
  
### 2. Communication-Efficient & Converge fast
* [Communication-Efficient Learning of Deep Networks from Decentralized Data](https://arxiv.org/pdf/1602.05629.pdf) 
* [Federated Learning for Wireless Communications: Motivation, Opportunities and Challenges](https://arxiv.org/pdf/1908.06847v3.pdf)
### 3. 针对模型和数据隐私的攻击/保护
* [Practical Secure Aggregation for Privacy-Preserving Machine Learning](https://eprint.iacr.org/2017/281.pdf)
### 4. 数据分布不均、数据异构
### 5. 激励机制
* [Fair Resource Allocation in Federated Learning](https://arxiv.org/pdf/1905.10497v1.pdf)
### 6. 其他
* [Federated Adversarial Domain Adaptation](https://arxiv.org/abs/1911.02054)
* [Federated Learning with Matched Averaging](https://arxiv.org/abs/2002.06440)
* [Bayesian Nonparametric Federated Learning of Neural Networks](https://arxiv.org/abs/1905.12022v1)
